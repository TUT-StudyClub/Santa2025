paths:
  baseline: "submissions/submission.csv"
  baseline_fallback: "submissions/baseline.csv"
  output: "submissions/submission.csv"

tree_shape:
  trunk_w: 0.15
  trunk_h: 0.2
  base_w: 0.7
  mid_w: 0.4
  top_w: 0.25
  tip_y: 0.8
  tier_1_y: 0.5
  tier_2_y: 0.25
  base_y: 0.0
  trunk_bottom_y: -0.2

optimization:
  # 最適化するグループ範囲
  n_min: 2
  n_max: 200

  # 対象グループ指定（空なら top_k で自動選択）
  target_groups: []
  target_top_k: 30
  target_range: [2, 80]

  # SSA パラメータ
  ssa:
    pop_size: 32
    n_iters: 1200
    pd_ratio: 0.2
    sd_ratio: 0.1
    st: 0.8
    danger_beta: 1.0

    # 初期化（ベースライン周りの摂動）
    init_pos_delta: 0.06
    init_ang_delta: 8.0
    init_tries: 30

    # 反復中のノイズ（局所探索の温度のように減衰）
    pos_delta: 0.03
    ang_delta: 6.0

    # 探索境界（基準の bounding side に対する倍率）
    pos_bound_scale: 2.0
    ang_bound: 45.0

    # 重なりが出たときの修復（二分探索の回数）
    repair_steps: 12

    # 乱数シード
    seed_base: 2042

    # 詳細ログ
    debug: false

  # --- GLS (Penalty Learning) Parameters ---
    # 重なり量に対する基本ペナルティ係数
    # (大きくするほど「重なり」を嫌うようになる)
    # 評価関数の変更により、penalty_scaleでスケーリングされるため、値を調整
    gls_alpha: 800.0  # 500.0から800.0に増加（固定ペナルティ削除の補償）

    # 学習した重みに対するペナルティ係数
    # (大きくするほど「過去に重なった場所」を強く避けるようになる)
    # 重み更新が控えめになったため、値を調整
    gls_beta: 300.0  # 200.0から300.0に増加（重み更新が控えめになった補償）

    # 重みを更新する頻度 (イテレーション回数)
    # (小さくすると学習が早いが、局所解にハマりやすくなる場合も)
    # 重み更新が控えめになったため、頻度を上げても問題ない
    gls_interval: 15  # 20から15に短縮（より頻繁に更新）

  # --- 無限ループ設定 ---
  infinite_loop:
    # 無限ループを有効にするか
    enable: false

    # 最大実行時間（秒）
    # デフォルト: 3600秒（1時間）
    max_time_seconds: 3600.0

    # 最大試行回数
    # デフォルト: 10回
    max_attempts: 10

    # 最小改善閾値（この値以上の改善がない場合は最良解を更新しない）
    # デフォルト: 1e-6
    min_improvement_threshold: 1e-6

    # ランダムリスタート確率（無限ループ時、この確率でベースラインから再開）
    # デフォルト: 0.3（30%の確率）
    random_restart_prob: 0.3
